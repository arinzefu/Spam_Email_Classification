{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:40:53.903041600Z",
     "start_time": "2024-01-17T12:40:42.056764100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dell 5590 i7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('combined_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:40:56.202939Z",
     "start_time": "2024-01-17T12:40:53.906032400Z"
    }
   },
   "id": "6abfff802583589d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>ounce feather bowl hummingbird opec moment ala...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>wulvob get your medircations online qnb ikud v...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>computer connection from cnn com wednesday es...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>university degree obtain a prosperous future m...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>thanks for all your answers guys i know i shou...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:40:56.239920300Z",
     "start_time": "2024-01-17T12:40:56.216935400Z"
    }
   },
   "id": "605a9d95163a3080"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(83448, 2)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:40:56.253858700Z",
     "start_time": "2024-01-17T12:40:56.233913Z"
    }
   },
   "id": "7ce64640866eb011"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    43910\n",
      "0    39538\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = data['label'].value_counts()\n",
    "print(counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:40:56.298833700Z",
     "start_time": "2024-01-17T12:40:56.264830500Z"
    }
   },
   "id": "b0ce0d410b9dd79c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:40:57.559592200Z",
     "start_time": "2024-01-17T12:40:56.281329800Z"
    }
   },
   "id": "7c4a6713409923b8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())  # Lowercase text\n",
    "data['text'] = data['text'].str.replace('[^\\w\\s]', '', regex=False)  # Remove punctuation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:40:57.954468100Z",
     "start_time": "2024-01-17T12:40:57.563581600Z"
    }
   },
   "id": "270a5a2d7e52f779"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset: 326251\n"
     ]
    }
   ],
   "source": [
    "num_words_in_dataset = data['text'].str.split().explode().nunique()\n",
    "\n",
    "print(f\"Number of unique words in the dataset: {num_words_in_dataset}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:41:02.731365600Z",
     "start_time": "2024-01-17T12:40:57.957458500Z"
    }
   },
   "id": "487c5c16e7e600d3"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# Train the Word2Vec model\n",
    "corpus = [doc.split() for doc in data['text']]\n",
    "Word2Vecmodel = Word2Vec(sentences=corpus, vector_size=100, window=10, min_count=3, workers=6)\n",
    "# Tokenize text data\n",
    "tokenizer = Tokenizer(num_words=num_words_in_dataset, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:42:36.130408400Z",
     "start_time": "2024-01-17T12:41:02.734356900Z"
    }
   },
   "id": "283dedd969ae702e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:42:36.171024100Z",
     "start_time": "2024-01-17T12:42:36.134397600Z"
    }
   },
   "id": "5f531d0d1e83e32e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Convert text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
    "val_sequences = tokenizer.texts_to_sequences(val_data['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:42:51.453832300Z",
     "start_time": "2024-01-17T12:42:36.162051100Z"
    }
   },
   "id": "86233317343e5767"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "train_padded = pad_sequences(train_sequences, maxlen=256, truncating='post', padding='post')\n",
    "val_padded = pad_sequences(val_sequences, maxlen=256, truncating='post', padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=256, truncating='post', padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:42:52.333521500Z",
     "start_time": "2024-01-17T12:42:51.486145200Z"
    }
   },
   "id": "16390f9deaf0fb11"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Define the vocabulary size and embedding matrix\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, 100))  \n",
    "for word, i in word_index.items():\n",
    "    if word in Word2Vecmodel.wv.key_to_index:\n",
    "        embedding_matrix[i] = Word2Vecmodel.wv[word]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:42:53.038909300Z",
     "start_time": "2024-01-17T12:42:52.333521500Z"
    }
   },
   "id": "266c66b74047ea2b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#define hypermaraters\n",
    "embedding_dim = 200\n",
    "max_length = 256\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:42:53.051874500Z",
     "start_time": "2024-01-17T12:42:53.045892600Z"
    }
   },
   "id": "2347ed79a8482b4"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, LSTM, GlobalMaxPooling1D, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T23:21:38.677545600Z",
     "start_time": "2024-01-17T23:21:38.638642700Z"
    }
   },
   "id": "6efdeb66111d55f5"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    Dropout(0.2),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    LSTM(32, return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='BinaryCrossentropy', optimizer=opt, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T23:21:45.779107Z",
     "start_time": "2024-01-17T23:21:43.982334100Z"
    }
   },
   "id": "d4e18daac4eb2345"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 256, 200)          64717200  \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256, 200)          0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 252, 128)          128128    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 252, 128)          512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 252, 64)           49408     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 252, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 252, 32)           12416     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 252, 32)           128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Gl  (None, 32)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64910481 (247.61 MB)\n",
      "Trainable params: 64909905 (247.61 MB)\n",
      "Non-trainable params: 576 (2.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T23:21:52.002486800Z",
     "start_time": "2024-01-17T23:21:51.915114400Z"
    }
   },
   "id": "50c4ca6ffd01f836"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1044/1044 [==============================] - 689s 660ms/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 0.0622 - val_accuracy: 0.9811\n",
      "Epoch 2/5\n",
      "1044/1044 [==============================] - 674s 645ms/step - loss: 0.0365 - accuracy: 0.9886 - val_loss: 0.0655 - val_accuracy: 0.9803\n",
      "Epoch 3/5\n",
      "1044/1044 [==============================] - 669s 641ms/step - loss: 0.0355 - accuracy: 0.9886 - val_loss: 0.0951 - val_accuracy: 0.9692\n",
      "Epoch 4/5\n",
      "1044/1044 [==============================] - 680s 651ms/step - loss: 0.0408 - accuracy: 0.9869 - val_loss: 0.0678 - val_accuracy: 0.9789\n",
      "Epoch 5/5\n",
      "1044/1044 [==============================] - 707s 678ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0604 - val_accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_padded, train_data['label'], validation_data=(val_padded, val_data['label']), epochs=5, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:42:19.949928300Z",
     "start_time": "2024-01-18T05:45:20.428881300Z"
    }
   },
   "id": "522bd32ea7349ae9"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 18s 67ms/step - loss: 0.0748 - accuracy: 0.9777\n",
      "Test Loss: 0.07479731738567352\n",
      "Test Accuracy: 0.9777112007141113\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_padded, test_data['label'])\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:51:51.826464200Z",
     "start_time": "2024-01-18T06:51:34.034023600Z"
    }
   },
   "id": "9747dffa24e41dac"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell 5590 i7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "model.save('Spam_Classification_model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:53:10.341627300Z",
     "start_time": "2024-01-18T06:52:50.123969500Z"
    }
   },
   "id": "d7068f8a8e0e762"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "Not Spam Confidence: 68.34%\n",
      "Prediction: Positive (Not Spam)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on custom text\n",
    "\n",
    "sample_text = 'Nigeria on Tuesday destroyed 2.5 tonnes of seized elephant tusks valued at over 9.9 billion naira ($11.2 million) in a push to protect its dwindling elephant population from rampant wildlife traffickers. Over the past three decades, Nigeriaâ€™s elephant population has declined drastically from an estimated 1,500 to less than 400 due to poaching for ivory, habitat loss and human-elephant conflict, according to conservationists.'\n",
    "\n",
    "# Convert the text to a padded sequence\n",
    "sequence = tokenizer.texts_to_sequences([sample_text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Get the probability of being spam\n",
    "probability = model.predict(padded_sequence)[0][0]\n",
    "\n",
    "# Determine spam based on the confidence level\n",
    "confidence_level = round(probability * 100, 2)\n",
    "\n",
    "if probability > 0.5:\n",
    "    print(f\"Spam Confidence: {confidence_level}%\")\n",
    "    print(\"Prediction: Negative (Spam)\")\n",
    "else:\n",
    "    print(f\"Not Spam Confidence: {100 - confidence_level}%\")\n",
    "    print(\"Prediction: Positive (Not Spam)\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T07:22:19.713507900Z",
     "start_time": "2024-01-18T07:22:19.581970700Z"
    }
   },
   "id": "782cc26295d6fcaa"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "Negative (Spam) with Confidence: 99.51%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_text_1 = 'Hey Trybers! Jojo is here...but Jojo is sad. Japa syndrome has caught up with me. See, what no one talks about is how japa syndrome is affecting friendships. You cannot even build long-term relationships because before you know it, they are leaving for Slovakia. On one hand, you are happy for them. Yunno, you can just slip in a conversation about how you talked to your friend in the US or disturb them for dollars. On the other hand, you are losing real friendship bonds. Damn. '\n",
    "\n",
    "# Convert the text to a padded sequence\n",
    "sequence = tokenizer.texts_to_sequences([sample_text_1])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Get the probability of being spam\n",
    "probability = model.predict(padded_sequence)[0][0]\n",
    "\n",
    "# Determine spam based on the confidence level\n",
    "confidence_level = round(probability * 100, 2)\n",
    "\n",
    "if probability > 0.5:\n",
    "    print(f\"Negative (Spam) with Confidence: {confidence_level}%\")\n",
    "else:\n",
    "    print(f\"Positive (Not Spam) with Confidence: {100 - confidence_level}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T07:06:50.958101900Z",
     "start_time": "2024-01-18T07:06:50.813265700Z"
    }
   },
   "id": "2b89c35956b84cc"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://279d3e9394986548c3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"https://279d3e9394986548c3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def classify_spam(text):\n",
    "    # Convert the text to a padded sequence\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "    # Get the probability of being spam\n",
    "    probability = model.predict(padded_sequence)[0][0]\n",
    "\n",
    "    # Determine spam based on the confidence level\n",
    "    confidence_level = round(probability * 100, 2)\n",
    "\n",
    "    if probability > 0.5:\n",
    "        result = f\"Negative (Spam) with Confidence: {confidence_level}%\"\n",
    "    else:\n",
    "        result = f\"Positive (Not Spam) with Confidence: {100 - confidence_level}%\"\n",
    "\n",
    "    return result\n",
    "\n",
    "# Create a Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=classify_spam,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    live=True, \n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "iface.launch(share=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T08:11:15.476897300Z",
     "start_time": "2024-01-18T08:10:45.539063100Z"
    }
   },
   "id": "6258c581efc9bfe8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
